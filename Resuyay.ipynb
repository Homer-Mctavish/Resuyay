{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24633e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.12.1+cu102\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "import textract\n",
    "import PyPDF2\n",
    "import en_core_web_sm\n",
    "from spacy.pipeline import EntityRuler\n",
    "from spacy import displacy\n",
    "import jsonlines\n",
    "import spacy\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "import re\n",
    "import zipfile\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import datetime\n",
    "from itertools import compress\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForPreTraining, \\\n",
    "                         AdamW, get_linear_schedule_with_warmup, \\\n",
    "                         TrainingArguments, BeamScorer, Trainer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, \\\n",
    "                             RandomSampler, SequentialSampler\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3f5de3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG           = False\n",
    "\n",
    "INPUT_DIR       = 'articles'\n",
    "\n",
    "#USE_APEX        = True\n",
    "#APEX_OPT_LEVEL  = 'O1'\n",
    "\n",
    "MODEL           = 'gpt2' #{gpt2, gpt2-medium, gpt2-large, gpt2-xl}\n",
    "\n",
    "UNFREEZE_LAST_N = 6 #The last N layers to unfreeze for training\n",
    "\n",
    "SPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n",
    "                    \"eos_token\": \"<|EOS|>\",\n",
    "                    \"unk_token\": \"<|UNK|>\",                    \n",
    "                    \"pad_token\": \"<|PAD|>\",\n",
    "                    \"sep_token\": \"<|SEP|>\"}\n",
    "                    \n",
    "MAXLEN          = 768  #{768, 1024, 1280, 1600}\n",
    "\n",
    "TRAIN_SIZE      = 0.8\n",
    "\n",
    "# if USE_APEX:\n",
    "#     TRAIN_BATCHSIZE = 4\n",
    "#     BATCH_UPDATE    = 16\n",
    "# else:\n",
    "TRAIN_BATCHSIZE = 2\n",
    "BATCH_UPDATE    = 32\n",
    "\n",
    "EPOCHS          = 4\n",
    "LR              = 5e-4\n",
    "EPS             = 1e-8\n",
    "WARMUP_STEPS    = 1e2\n",
    "\n",
    "SEED            = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8d91d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained English language model\n",
    "# nlp = nl_core_news_sm.load()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# File Extension. set as 'pdf' or as 'doc(x)'\n",
    "extension = 'pdf'\n",
    "diro='/home/absconditus/Documents/Github/Python Projects/jupyter/TF LSTM RNN for cover letter generation/Workfiles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "08112bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file):\n",
    "    '''Opens and reads in a PDF file from path'''\n",
    "    \n",
    "    fileReader = PyPDF2.PdfFileReader(open(file,'rb'))\n",
    "    page_count = fileReader.getNumPages()\n",
    "    text = [fileReader.getPage(i).extractText() for i in range(page_count)]\n",
    "    \n",
    "    return str(text).replace(\"\\\\n\", \"\")\n",
    "\n",
    "def extract_text_from_word(filepath):\n",
    "    '''Opens and reads in a .doc or .docx file from path'''\n",
    "    \n",
    "    txt = textract.process(filepath).decode('utf-8')\n",
    "    \n",
    "    return txt.replace('\\n', ' ').replace('\\t', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e783a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokenized_texts_list(extension):\n",
    "    '''Create two lists, one with the names of the candidate and one with the tokenized \n",
    "       resume texts extracted from either a .pdf or .doc'''\n",
    "    resume_texts, resume_names = [], []\n",
    "    \n",
    "    # Loop over the contents of the directory containing the resumes, filtering by .pdf or .doc(x)\n",
    "    for resume in list(filter(lambda x: extension in x, os.listdir(diro + '/CV'))):\n",
    "        if extension == 'pdf':\n",
    "            # Read in every resume with pdf extension in the directory\n",
    "            resume_texts.append(nlp(extract_text_from_pdf(diro + '/CV/' + resume)))\n",
    "        elif 'doc' in extension:\n",
    "            # Read in every resume with .doc or .docx extension in the directory\n",
    "            resume_texts.append(nlp(extract_text_from_word(diro + '/CV/' + resume)))\n",
    "            \n",
    "        resume_names.append(resume.split('_')[0].capitalize())\n",
    "        \n",
    "    return resume_texts, resume_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "9ad5cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_newruler_to_pipeline(skill_pattern_path):\n",
    "    '''Reads in all created patterns from a JSONL file and adds it to the pipeline after PARSER and before NER'''\n",
    "    \n",
    "    new_ruler = EntityRuler(nlp).from_disk(skill_pattern_path)\n",
    "    nlp.add_pipe(new_ruler, after='parser')\n",
    "    \n",
    "\n",
    "def visualize_entity_ruler(entity_list, doc):\n",
    "    '''Visualize the Skill entities of a doc'''\n",
    "    \n",
    "    options = {\"ents\": entity_list}\n",
    "    displacy.render(doc, style='ent', options=options)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b9577131",
   "metadata": {},
   "outputs": [],
   "source": [
    "skillz = \"/home/absconditus/Documents/Github/Python Projects/jupyter/TF LSTM RNN for cover letter generation/Workfiles/Skill_List/skill_patterns.jsonl\"\n",
    "with jsonlines.open(skillz) as f:\n",
    "    created_entities = [line['label'].upper() for line in f.iter()]\n",
    "\n",
    "ruler = EntityRuler(nlp).from_disk(skillz)\n",
    "nlp.add_pipe(ruler, after='parser')\n",
    "\n",
    "def get_skills(text):\n",
    "    doc = nlp(text)\n",
    "    myset = []\n",
    "    subset = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_==\"SKILL\":\n",
    "             subset.append(ent.text)\n",
    "    myset.append(subset)\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8e8f1fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texer = open(\"/home/absconditus/Documents/Github/Python Projects/jupyter/TF LSTM RNN for cover letter generation/Workfiles/Cover_Letters/UI_UX Designer - 1000 tokens.txt\")\n",
    "texo = open(\"/home/absconditus/Documents/Github/Python Projects/jupyter/TF LSTM RNN for cover letter generation/Workfiles/Cover_Letters/Digital Marketing Consultant - 500 tokens.txt\")\n",
    "datto = texer.read()\n",
    "datum = texo.read()\n",
    "\n",
    "texo.close()\n",
    "texer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ba14cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cha = extract_text_from_pdf(\"/home/absconditus/Documents/Github/Python Projects/jupyter/TF LSTM RNN for cover letter generation/Workfiles/Resume/Resume.pdf\")\n",
    "\n",
    "#open text file in read mode\n",
    "text_file = open(\"/home/absconditus/Documents/Github/Python Projects/jupyter/TF LSTM RNN for cover letter generation/Workfiles/Cover_Letters/Data Specialist-500 tokens.txt\", \"r\")\n",
    " \n",
    "#read whole file to a string\n",
    "data = text_file.read()\n",
    "\n",
    "#close file\n",
    "text_file.close()\n",
    "\n",
    "pb = pd.DataFrame(\n",
    "    columns=['title','body']\n",
    "    )\n",
    "pb.loc[0]='Data Specialist',data\n",
    "pb.loc[1]='Idiot', cha\n",
    "pb.loc[2]='UX_UI Designer', datum\n",
    "pb.loc[3]='Digital Marketing Consultant', datto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2031b3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Specialist</td>\n",
       "      <td>Beginning - manual input:\\nDear Ms. Mustermann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Idiot</td>\n",
       "      <td>['Samuel SpearingFairfield, Connecticut • (203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UX_UI Designer</td>\n",
       "      <td>Beginning - manual input:\\nDear Ms. Mustermann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Digital Marketing Consultant</td>\n",
       "      <td>Beginning - manual input:\\nDear Ms. Mustermann...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  \\\n",
       "0               Data Specialist   \n",
       "1                         Idiot   \n",
       "2                UX_UI Designer   \n",
       "3  Digital Marketing Consultant   \n",
       "\n",
       "                                                body  \n",
       "0  Beginning - manual input:\\nDear Ms. Mustermann...  \n",
       "1  ['Samuel SpearingFairfield, Connecticut • (203...  \n",
       "2  Beginning - manual input:\\nDear Ms. Mustermann...  \n",
       "3  Beginning - manual input:\\nDear Ms. Mustermann...  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "90200bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb['skills']=pb['body'].apply(get_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "463cf16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "b6320062",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, tokenizer, randomize=True):\n",
    "\n",
    "        title, text, keywords = [], [], []\n",
    "        for v in range(len(data)):\n",
    "            title.append(data['title'][v])\n",
    "            text.append(data['body'][v])\n",
    "            keywords.append(data['skills'][v])\n",
    "\n",
    "        self.randomize = randomize\n",
    "        self.tokenizer = tokenizer \n",
    "        self.title     = title\n",
    "        self.text      = text\n",
    "        self.keywords  = keywords  \n",
    "\n",
    "    @staticmethod\n",
    "    def join_keywords(keywords, randomize=True):\n",
    "        N = len(keywords)\n",
    "\n",
    "        #random sampling and shuffle\n",
    "        if randomize: \n",
    "            M = random.choice(range(N+1))\n",
    "            keywords = keywords[:M]\n",
    "            random.shuffle(keywords)\n",
    "\n",
    "        return ','.join(keywords)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getBit(self):\n",
    "        keywords = self.keywords[i].copy()\n",
    "        kw = self.join_keywords(keywords, self.randomize)\n",
    "        return kw\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        keywords = self.keywords[i].copy()\n",
    "        kw = self.join_keywords(keywords, self.randomize)\n",
    "        \n",
    "        input = SPECIAL_TOKENS['bos_token'] + self.title[i] + \\\n",
    "                SPECIAL_TOKENS['sep_token'] + kw + SPECIAL_TOKENS['sep_token'] + \\\n",
    "                self.text[i] + SPECIAL_TOKENS['eos_token']\n",
    "\n",
    "        encodings_dict = tokenizer(input,                                   \n",
    "                                   truncation=True, \n",
    "                                   max_length=MAXLEN, \n",
    "                                   padding=\"max_length\")   \n",
    "        \n",
    "        input_ids = encodings_dict['input_ids']\n",
    "        attention_mask = encodings_dict['attention_mask']\n",
    "        \n",
    "        return {'label': torch.tensor(input_ids),\n",
    "                'input_ids': torch.tensor(input_ids), \n",
    "                'attention_mask': torch.tensor(attention_mask)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1d5f1426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'body', 'skills']\n"
     ]
    }
   ],
   "source": [
    "ivso = list(pb.keys())\n",
    "idso = ivso[:2+1]\n",
    "ibso = ivso[2:]\n",
    "print(idso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2a6fb55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, S=TRAIN_SIZE):\n",
    "    # Shuffle ids\n",
    "    ids = list(data.keys())\n",
    "    random.shuffle(ids)\n",
    "\n",
    "    # Split into training and validation sets    \n",
    "    train_size = int(S * len(data))\n",
    "\n",
    "    train_ids = ids[:train_size+1]\n",
    "    val_ids = ids[train_size:]\n",
    "\n",
    "    train_data = dict()\n",
    "    for id in train_ids:\n",
    "        train_data[id] = data[id]\n",
    "\n",
    "    val_data = dict()\n",
    "    for id in val_ids:\n",
    "        val_data[id] = data[id]\n",
    "\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "2c634a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'body', 'skills']\n"
     ]
    }
   ],
   "source": [
    "data = pb.to_dict()\n",
    "ids = list(data.keys())\n",
    "print(ids[:3+1])\n",
    "# bobi, zobi = split_data(pb.to_dict())\n",
    "# bobi.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "571a55ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Specialist\n",
      "Data Specialist\n",
      "Data Specialist\n"
     ]
    }
   ],
   "source": [
    "data = pb.to_dict()\n",
    "k, d = split_data(data)\n",
    "b = []\n",
    "for i in range(3):\n",
    "    print(k['title'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "0dc8b2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "title, text, keywords = [], [], []\n",
    "for v in range(len(data)):\n",
    "            title.append(data['title'][v])\n",
    "            text.append(data['body'][v])\n",
    "            keywords.append(data['skills'][v])\n",
    "print(len(keywords.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "c1b48ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenier(special_tokens=None):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL) #GPT2Tokenizer\n",
    "\n",
    "    if special_tokens:\n",
    "        tokenizer.add_special_tokens(special_tokens)\n",
    "        print(\"Special tokens added\")\n",
    "    return tokenizer\n",
    "\n",
    "def get_model(tokenizer, special_tokens=None, load_model_path=None):\n",
    "\n",
    "    #GPT2LMHeadModel\n",
    "    if special_tokens:\n",
    "        config = AutoConfig.from_pretrained(MODEL, \n",
    "                                            bos_token_id=tokenizer.bos_token_id,\n",
    "                                            eos_token_id=tokenizer.eos_token_id,\n",
    "                                            sep_token_id=tokenizer.sep_token_id,\n",
    "                                            pad_token_id=tokenizer.pad_token_id,\n",
    "                                            output_hidden_states=False)\n",
    "    else: \n",
    "        config = AutoConfig.from_pretrained(MODEL,                                     \n",
    "                                            pad_token_id=tokenizer.eos_token_id,\n",
    "                                            output_hidden_states=False)    \n",
    "\n",
    "    \n",
    "    model = AutoModelForPreTraining.from_pretrained(MODEL, config=config)\n",
    "\n",
    "    if special_tokens:\n",
    "        #Special tokens added, model needs to be resized accordingly\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if load_model_path:\n",
    "        model.load_state_dict(torch.load(load_model_path))\n",
    "\n",
    "    #model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "718bd7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/absconditus/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /home/absconditus/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /home/absconditus/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /home/absconditus/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/absconditus/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "Assigning <|BOS|> to the bos_token key of the tokenizer\n",
      "Assigning <|EOS|> to the eos_token key of the tokenizer\n",
      "Assigning <|UNK|> to the unk_token key of the tokenizer\n",
      "Assigning <|PAD|> to the pad_token key of the tokenizer\n",
      "Assigning <|SEP|> to the sep_token key of the tokenizer\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/absconditus/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50258,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50260,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"sep_token_id\": 50261,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /home/absconditus/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.81 s, sys: 479 ms, total: 7.29 s\n",
      "Wall time: 3.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\n",
    "model = get_model(tokenizer, \n",
    "                  special_tokens=SPECIAL_TOKENS,\n",
    "                #   load_model_path='pytorch_model.bin'\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "490790c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Freeze selective layers:\n",
    "# - Freeze all layers except last n:\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "for i, m in enumerate(model.transformer.h):        \n",
    "    #Only un-freeze the last n transformer blocks\n",
    "    if i+1 > 12 - UNFREEZE_LAST_N:\n",
    "        for parameter in m.parameters():\n",
    "            parameter.requires_grad = True \n",
    "\n",
    "for parameter in model.transformer.ln_f.parameters():        \n",
    "    parameter.requires_grad = True\n",
    "\n",
    "for parameter in model.lm_head.parameters():        \n",
    "    parameter.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "fc0e52b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'body': {0: 'Beginning - manual input:\\nDear Ms. Mustermann, with this letter and attached resume, I would like to express my sincere interest in the vacancy for ‘Data Specialist’.\"\\n===============================================================================================================================================================\\n\\nAs a highly skilled and highly accomplished professional with comprehensive expertise in performing all facets of data entry and data management, I am confident that I would significantly contribute to the success of your organization.\\n\\nMy career accomplishments include more than four years of experience in positions of increasing responsibility within the Data Entry and Analysis Center at Juniper Systems. In addition to this, my comprehensive knowledge of quality assurance and storage techniques is certain to render me an asset to your organization. Furthermore, my superior communication and problem-solving skills position me to make a significant and positive impact on your organization.\\n\\nThe following achievements highlight my qualifications for this position:\\n\\n Increased data entry and data management efficiency by 32% and 46% across all blue team sites across multiple assignments across multiple data centers across the Midwest region; led teams through the creation of detailed descriptions of each sample item, along with the corresponding sample conditionals, and conditionals followed by the corresponding results.\\n\\n Led teams through the creation of detailed descriptions of each sample item, along with corresponding results.\\n\\n Led through and executed a drastic reduction in data entry and data loss by 36%, 41%, and 19%, respectively, across three data centers across the Midwest region.\\n\\n Led teams through the creation of detailed descriptions of each sample item, along with a sample condition—’to facilitate the proper handling and presentation of data by Juniper Systems.\\n\\n Led through major enhancements to the Juniper system by analyzing the data and introducing a new conditionals procedure to enhance the efficiency of the Juniper sample analysis process.\\n\\n Improved database performance by 46% by introducing a new operations database to optimize performance of all the data entry databases in Juniper.\\n\\n Implemented a data migration from a current 90KB monthly cycle to a new 32KB monthly cycle, maximizing efficiency at reducing incoming transaction costs.\\n\\n Maintained a significantly improved database with over 60,000 registered users across all databases.\\n\\n Achieved an overall completion rate of 87.9%, including all testing.\\n\\nMy proven dedication to facilitating efficient and accurate data entry and analysis for Juniper Systems, along with my exceptional analytical and problem-solving talents, will contribute immensely to the success of your team. Thank you for your consideration, and I look forward to speaking with you soon.\\n\\n\\n====================\\n As an experienced and motivated professional with more than seven years of experience driving high-performance, data-driven operations, I possess a range of knowledge and skills that will allow me to contribute toward the success of your organization.\\n\\nMy expertise lies in successfully creating, maintaining, and rolling out new systems and processes, as well as overseeing testing and troubleshooting operations to ensure all systems and processes meet corporate goals. Through my experience, I have become well versed in overseeing a wide variety of data management and analysis tasks, while simultaneously ensuring top-level accuracy and attention to detail. My additional success in building key relationships through key partnerships positions me to make a significant contribution to your organization.\\n\\nThe following achievements demonstrate my qualification for this position:\\n\\n Spearheading data collection, presentation, and data processing operations for multiple organizations, working collaboratively with a highly accomplished executive team at JPI Systems, culminating in the role of Data Specialist.\\n\\n Developing strategic initiatives and plans to propel sales performance while managing vendor negotiations and leading high-performance teams to achieve maximum productivity and efficiency.\\n\\n Analyzing and managing comprehensive documentation, records, and reportkeeping systems while optimizing operational strategies and mitigating risk by analyzing operations through dynamic analytical thinking and documentation.\\n\\n Managing a range of project management and client relationship responsibilities, including scheduling, calendars, mock presentations, RFPs, and issue resolution.\\n\\n Producing detailed, comprehensive documentation, including correspondence and project management, to all parties to ensure implementation and execution.\\n\\n Demonstrating superior communication and relationship management talents.\\n\\nMy proven success in meeting corporate data goals, along with my comprehensive expertise in driving data quality and progress, will contribute immensely to the success of your organization. Thank you for your consideration; I look forward to speaking with you soon.\\n\\n\\n====================\\n As an analytical and top-performing professional with a strong history of supporting and exceeding data integrity and quality, I possess the skills and qualifications to enable me to contribute toward the success of your organization.\\n\\nMy experience includes successfully analyzing customer data sets to drive data quality and consistency, and subsequently leading support teams to respond to and resolve data problems. My established success in advising senior executives on data breaches and other critical issues—along with my expertise in comprehensive data analysis tools and systems—positions me to make a significant and positive impact on your organization.\\n\\nConsider the following highlights of my achievements:\\n\\n Excelled as a Data Specialist with Next Level Manufacturing for the past six years, supporting data entry and quality control with the production of more than 550,000 units.\\n\\n Led all aspects of quality assurance—including audits and work releases—for all production lines during my tenure with Next Level Manufacturing.\\n\\n Provided essential team leadership, such as keeping line engineers motivated and running tests and copy edits to ensure goal achievement.\\n\\n Led all phases of quality control studies; preparing reports, maintaining Excel spreadsheets, and developing specifications for each production line to ensure proper functioning.\\n\\n Played a key role in improving process efficiency by assigning tasks to more employees and reducing downtime.\\n\\n Earned a Bachelor’s degree in Engineering from Duke University.\\n\\nMy proven dedication to optimizing product integration and customer support, along with my excellent analytical and problem-solving talents, will contribute immensely to the success of your company. Thank you for your consideration, and I look forward to speaking with you soon.\\n\\n\\n====================\\n As a highly skilled and accomplished professional with more than 11 years of experience assisting and strategizing with data collection and data management, I am confident that I would significantly contribute to the success of your team.\\n\\nMy experience lies in successfully facilitating the data collection, analysis, and analysis of various medical articles from various sources, as well as in providing overarching administrative and operational support to senior management teams. Throughout my career, I have demonstrated an unparalleled dedication to providing outstanding support within fast-paced, customer-facing environments. Additionally, my demonstrated success in overseeing administrative and operational strategies within healthcare industry organizations, positions me to make a significant impact on your organization.\\n\\nThe following achievements demonstrate my qualification for this position:\\n\\n Propelling research productivity and quantile growth, improving efficiency by 28%, reducing expenses by 24%, and improving accuracy by 31%.\\n\\n Facilitating the participation of medical teams and marketing teams to identify and recommended treatment plans to meet patient needs and expectations.\\n\\n Communicating effectively with physicians, nurses, medical assistants, and senior management staff to facilitate highly successful healthcare recruitment and management.\\n\\n Earning an MBA in Health Information Management from Western University; holding dual Master’s degrees in Medical Information and Management from the University of Pennsylvania.\\n\\nMy proven dedication to optimizing organizational success through my expert knowledge of medical research and management will contribute immensely to the success of your team. Thank you for your consideration, and I look forward to speaking with you soon.\\n\\n\\n====================\\n As a highly skilled and accomplished professional with extensive experience overseeing comprehensive data collection and manipulation, I possess a wide range of knowledge and abilities that will allow me to contribute toward the success of your organization.\\n\\nMy expertise lies in successfully analyzing complex data sets to identify and document weaknesses, gaps, and discrepancies. I excel at liaising with customers and implementing highly effective data management systems while continually completing appropriate training programs to advance skillful data analysis. Furthermore, my established success in supervising and motivating teams to top performance levels positions me to make a significant contribution to your organization.\\n\\nThe following achievements demonstrate my qualification for this position:\\n\\n Overseeing comprehensive data collection and management tasks within high-pressure environments while identifying and swiftly resolving errors and/or discrepancies.\\n\\n Developing and maintaining standard-setting compliance documents and tickets, maintaining conditioner stations and inspecting samples to maintain strict compliance.\\n\\n Creating and maintaining a variety of presentations, reports, KPIs, and RFP items, including requirement drawings and descriptions.\\n\\n Performing daily system audits and identifying performance gaps by analyzing methods and procedures implemented methodologies previously unfortunately attributed to management.\\n\\n Preparing to achieve a Master’s degree in Business Information Science from the University of California, San Diego.\\n\\nMy proven dedication to optimizing customer data service success through my expert knowledge of dynamic data management techniques will contribute immensely to the success of your team. Thank you for your consideration, and I look forward to speaking with you soon.\\n\\n\\n====================', 1: \"['Samuel SpearingFairfield, Connecticut • (203) 572-3492 •sonicrush77@gmail.com•Linkedin•GithubEDUCA TIONClark University, W orcester MAExpected2023Bachelor of Arts and Sciences in Computer Science, Minor in Mathematics,3.3 GP A, Deans List 2021SKILLSLanguages: Java, Scala, C++, C#, Python, Haxe, ROperating Systems:GNU/Linux, UNIX, Microsoft WindowsPC Software:Tensorflow , ASP .NET  Core, MA TLAB, Blender ,AutoCAD, Google G Suite,Microsoft Of fice Suite, LibreOf fice SuiteCertifications: AWS Certified Cloud PractitionerPROFESSIONAL  EXPERIENCESoftware DeveloperApril 2019 – June 2019EDR, Shelton, Connecticut●Designed a geographical data interpreter program for a corporate client●Worked with IT  staf f to fully automate the deployment of the environment●Migrated existing elevation maps to a new environmentin order to implement arcGIS andGDALmethods of data interpretation●Communicated project tracking through daily stand up meetings with project/internship managerLandscaperJune 2020 – August 2020Corrine’ s Garden Creations, Fairfield, Connecticut●Applied pesticides and fertilizers to grounds and lawns on a regular basis●Adhered to predetermined landscaping designs in all maintenance tasksAmazon W arehouse AssociateJune 2021 - August 2021Amazon Logistics, Orange, Connecticut●worked in teams to meet end of shift deadlines●worked in a very fast paced environment●duties included but not limited to: package scanning, stowing,unloading and staging●Top Stower during Prime W eek, obtained Top Ten Stower Status 5 weeks in a rowPROJECTSOnline Bank Management System●Online Bank Account Platform and DatabaseNetwork Packet Sniffer●Network Traffic Interceptor and LoggerETL●Raster Image Pyramid and Mosaic Dataset CLITensorflow DNN●A Deep Learning Neural Network for Identifying Counterfeit BillsNatural Language Processing Network●Natural Language Interpretation Processor for Yelp ReviewsLending Club Random Forest Model●Random Forest Prediction Model for Debt RepaymentDEMONSTRA TED LEADERSHIPSikorsky STEM Challenge Leader, Sikorsky STEM ChallengeJune 2016 - April 2019Club T reasurer ,Science Fiction People Of ClarkApril 2021-Present']\", 2: 'Beginning - manual input:\\nDear Ms. Mustermann, with this letter and attached resume, I would like to express my sincere interest in the vacancy for ‘Digital Marketing Consultant’.\"\\n===============================================================================================================================================================\\n\\nAs an accomplished and driven professional with 12+ years of experience driving successful campaign execution and digital marketing strategies, I possess a wide range of knowledge and experience that will allow me to contribute toward the success of your company.\\n\\nMy background includes successfully leading marketing management teams to define and pursue strategic marketing initiatives to realize multimillion-dollar revenue increases. With strong inner motivation and high-energy business acumen, I excel in spearheading marketing strategy development, development, and execution to realize top-level business growth and success.\\n\\nThe following achievements demonstrate my qualification for this position:\\n\\n Overseeing all facets of the marketing and PR strategies implemented between 2009 and 2015 for companies with a reported annual revenue of $4.7M.\\n\\n Spearheading marketing strategy development, demonstrating, and achieving – respectively – $11.6M and –$13.9M in annual revenue increases for major global retailers combined.\\n\\n Dramatically boosting corporate ROI through targeted marketing initiatives and highly effective web and social media strategies to maintain a premium on brand awareness and growth.\\n\\n Excelling in dynamic marketing train-up roles, demonstrating superior presentation, organization, and customer service talents.\\n\\nMy proven success in achieving corporate marketing goals and objectives, along with my comprehensive expertise in developing strategic initiatives and programs throughout all levels of the marketing cycle, will contribute immensely to the success of your team. Thank you for your consideration, and I look forward to speaking with you soon.\\n\\n\\n====================\\n As an accomplished and driven professional with 13+ years of experience driving successful \\n\\nmarketing communications\\n\\nand lead generation, I possess a breadth of knowledge and skills that will allow me to contribute toward the success of your company.\\n\\nMy expertise lies in successfully coordinating and leading marketing presentations, prospecting and securing partner agreements, and managing lead prospecting and relationship management. Additionally, my established success in building and maintaining a formidable client roster positions me to make a significant contribution in this role.\\n\\nThe following achievements demonstrate my qualification for this position:\\n\\n Spearheading the marketing communications team responsible for securing new business for Coldwater’s business shoe division; elevated the visibility of Coldwater’s vast roster by leveraging internal IT channels to educate and secure its customers.\\n\\n Overseeing marketing communications team—incorporating visual and multimedia tools’throughout all facets of development and growth for Coldwater to position itself as a prime target.\\n\\n Developing and securing new business opportunities through lead prospecting, networking, persuasion, and relationship building talents.\\n\\n Empowering junior team leaders to maintain up-to-date copy of corporate marketing and prospecting strategies; promoting product features and positioning campaigns to increase exposure and customer satisfaction.\\n\\n Demonstrating outstanding verbal and written communication skills while leveraging motivation, organization, and multitasking abilities to achieve maximum sales and the highest level of customer service.\\n\\nMy proven success in achieving corporate sales goals, along with my comprehensive expertise in successful marketing communications and development, will contribute immensely to the success of your team. Thank you for your consideration, and I look forward to speaking with you soon.\\n\\n\\n====================\\n As an accomplished and driven marketing professional with more than 16 years of experience driving successful marketing initiatives, I am confident that my skill set will significantly benefit your team.\\n\\nMy expertise lies in successfully connecting with key decision makers and implementing forward-thinking marketing plans to drive market impact and expansion for product launch and development efforts. With strong inner motivation and superior communication talents, I excel in spearheading project life cycles, streamlining operations, and maximizing brand awareness and awareness. Additionally, my proven ability to connect with key decision makers allows me to become a significant asset to your marketing team.\\n\\nThe following achievements demonstrate my qualification for this position:\\n\\n Spearheading project life cycles—including procuring necessary materials and coordinating with outside groups to drive market impact and expansion for product development efforts.\\n\\n Developing strategic plans to enable from-point-3 product integration while minimizing potential competitor efforts and drasticallyoverlapping sales.\\n\\n Demonstrating expertise in traditional and digital marketing channels to gather data and communicate marketing plans.\\n\\n Collaborating effectively with industry experts to ensure top-flight customer service and satisfaction while proactively tackling all but impossible projects.\\n\\nMy proven dedication to optimizing marketing strategies and executing launch operations for strategic goals in consecutive marketing leadership positions me to make a significant impact on your company. I look forward to discussing my qualifications with you further in the near future.\\n\\nThank you for your consideration.\\n\\n\\n====================\\n As an accomplished and driven marketing executive with more than 12 years of experience driving strategic marketing initiatives and overall business development efforts, I possess a wide range of knowledge and talents that will allow me to contribute toward the success of your company.\\n\\nMy expertise lies in successfully conceptualizing, implementing, and overseeing strategic marketing initiatives to drive market impact and expansion for company-wide product releases, strategic market analysis and selection efforts, and enhanced brand messaging. With proven success conducting in-depth market and competitive market research and overseeing high-profile client communications efforts, my additional strengths in training and managing top-performing teams will certainly benefit your organization.\\n\\nThe following achievements demonstrate my qualification for this position:\\n\\n Spearheading marketing communications initiatives for Waggle, Inc.; drafting press releases, annual financial reports, e-commerce invoices, and detailed prospecting and prospecting materials for customer-centric retail stores; researching and approving product releases to meet goals and needs, managing client relationships, and significantly increasing sales volumes for leading US retail chains\\n\\n Developing and implementing a new campaign strategy focused on digital sales growth; increasing bookings by 50% across all product categories, leading to a 56% increase in bookings boost in value of account over the course of the campaign\\n\\n Overseeing social media content for Waggle, Inc. and spearheading advertising content development for newstand.com, driving social media analytics and engagement, and optimizing website traffic to improve reader response rates\\n\\n Designing and implementing a new web analytics strategy, increasing site visits by 175% and SEM by 57% as digital marketing manager for stand-alone retail products company, while reducing affiliate costs by 65%\\n\\n Continually boosting profile pages for customer-specific product pages, optimizing their customer experience and boosting their search engine rankings by 470% as marketing manager for stand-alone retail product company, ShopRite, US\\n\\nWith my proven record of managing all business operations and managing high-impact projects, I am positioned to exceed your expectations for this role. I look forward to discussing the position and my qualifications in further detail. Thank you for your consideration.\\n\\n\\n====================\\n As a highly innovative and accomplished marketing and advertising professional with a strong history of success connecting with key clients to design successful advertising strategies, I think my educational background and passion for marketing are a great match for your needs.\\n\\nMy experience includes consulting with a wide variety of clients to analyze their needs, identify areas for improvement, and create marketing collateral to drive revenue growth. I think my strong academic record makes me a perfect fit for your company.\\n\\nThe following is a list of my most relevant skills and qualifications.\\n\\n Earned a Bachelor’s degree in Marketing and Advertising from Northwestern University\\n\\n Collaborated with clients to pitch products and services to achieve their unique needs\\n\\n Created marketing campaigns that gained highly specific attention from clients\\n\\n Gained professional experience in digital marketing campaigns\\n\\n Proficient at leveraging client communications expertise to advance campaigns\\n\\nI think what sets me apart from candidates with similar qualifications is my obsession with customer service. I would love to discuss your opportunity to become a part of the team at your company.', 3: 'Beginning - manual input:\\nDear Ms. Mustermann, with this letter and attached resume, I would like to express my sincere interest in the vacancy for ‘UI/UX Designer’.\"\\n===============================================================================================================================================================\\n\\nAs an accomplished and customer-centric professional with more than 13 years of experience designing and implementing user-friendly interface solutions to efficiently and successfully meet the needs of both end users and designers, I feel confident in my ability to significantly contribute to the success of your company.\\n\\nMy experience includes designing and implementing a broad range of user-friendly design solutions to drive market share, performance, and customer engagement. With my professional achievements, combined with my technical and customer service capabilities, I am confident that my talents and abilities will significantly benefit Yougalers.\\n\\nThe following achievements demonstrate my qualification for this position:\\n\\n Designing user interfaces to ensure seamless interface solutions and corresponding solutions to achieve customer needs and objectives.\\n\\n Spearheading the development and implementation of software features—including support, troubleshooting, integration, and deployment—as UI/UX designer for senior-level solutions vendor.\\n\\n Developing and maintaining user interfaces for major global companies including Pivotal, SAP, and Vantage.\\n\\n Accurately and expeditiously resolving user issues and maintaining a high volume of user input and feedback to achieve optimal experiences and customer requirements.\\n\\n Earning a Bachelor of Engineering in Computer Science from the University of Wisconsin.\\n\\nMy proven dedication to optimizing user interface design and development, along with my exceptional communication and analytical talents, will contribute immensely to the success of your team. Thank you for your consideration, and I look forward to speaking with you soon.\\n\\n\\n====================\\n As an accomplished and highly accomplished UI/UX professional with a strong history of leading product design efforts, I feel confident in my ability to exceed your expectations for this role.\\n\\nMy comprehensive career accomplishments include comprehensive experience designing and implementing highly successful in-house products while leading team members to design and achieve client objectives. Furthermore, I excel at consulting with clients to communicate key design decisions to managers while maintaining a sharp focus on optimizing client experiences and clients. With these attributes coupled with my Master’s degree in UI/UX design from the University of Florida, I am ready to deliver outstanding service for your organization.\\n\\nHighlights of my experience include the following:\\n\\n Directed all UI design efforts, including the user interface, into-page updates for the UI website of a company.\\n\\n Led the UI redesign of the website of a company, leading to an increase in users visiting the site twice as often as the previous design studio’s web product.\\n\\n Orchestrated major redesigns of the backend and frontend implementations of various design software implementations, leading to an increase in user referrals.\\n\\n Oversaw the design of a web-based tracking system for the site’s backend, resulting in a decrease of users’time spent on the site by 19%.\\n\\n Oversaw the design of a database implementation implementation implementation Amazon S3, leading to an increase in users’time on site by 16%.\\n\\n Created and maintained website templates and forms using WordPress and RedTech.org.\\n\\n Earned an MFA degree from the University of Florida, the same institution that supplied me with the coding and design skills I needed to progress to an MSA level.\\n\\nMy proven success in overseeing UI design projects, along with my exceptional interpersonal and analytical talents, will contribute immensely to the success of your team. Thank you for your consideration, and I look forward to speaking with you soon.\\n\\n\\n====================\\n As an accomplished and highly accomplished professional with extensive experience designing and implementing key components of software applications while managing projects throughout all phases from inception through execution, I am confident that I would significantly contribute to the objectives of your company.\\n\\nMy career accomplishments include outstanding experience as the UI/UX Designer at Quadriforce Ltd., leading design projects to implementation, test strategies, design implementation, and project lifecycle management. From overseeing development cycles and initial conceptual design phases to complete product delivery and successful completion, I excel at conceptualizing and creating functional and efficient UI/UX solutions to meet projected objectives, problem areas, and requirements.\\n\\nConsider the following highlights of my qualifications:\\n\\n Spearheading the design and implementation of Quadriforce Ltd.\\'s software development solutions program; led testing and best practice design cycles of all software products for Quadriforce Ltd.\\n\\n Scored highly on a 4:1 scale in a recent HR Poll regarding my ability to serve as the Lead UI/UX Designer for Blue Stream; elevated employee morale and enhanced company brand awareness\\n\\n Introduced a robust and efficient multi-tasking strategy to maximize functionality and usability, resulting in a decrease in user confusion and product malfunction.\\n\\n Exped UI/UX design by applying highly focused design principles to both individual users and corporate products, creating a more streamlined and streamlined interface that could reduce design downtime and costs.\\n\\n Earned a Bachelor of Science in Information Systems Engineering from the University of Texas, Austin.\\n\\nWith my record of success in UI/UX design, combined with my superior leadership and interpersonal abilities, I am ready to provide outstanding service within your company as your next UI/UX Designer. I look forward to discussing the position with you in further detail.\\n\\n\\n====================\\n As an accomplished and customer-centric professional with comprehensive experience designing and implementing front-end solutions to achieve goals for their products, I am confident in my ability to substantially benefit your company.\\n\\nMy background includes designing and developing products and services using HTML, CSS, and JavaScript to drive improved usability and usability. From correcting user interfaces and updating user interface components to forging strong customer relationships and overseeing quality assurance, I excel at overseeing strategic enhancements, which propel businesses to peak performances. Furthermore, I have consistently demonstrated expertise in overseeing vendor and supplier relationships to ensure continuity of business operations.\\n\\nFollowing are highlights of my qualifications:\\n\\n Propelling web design efforts to meet the needs of businesses and superior user experiences, using HTML, CSS, and JavaScript to design innovative new solutions and solutions to achieve client objectives\\n\\n Overseeing all aspects of design for high-impact client products, including web graphics, banners, advertising, branding, e-commerce, and email\\n\\n Developing trusting customer relationships to achieve client objectives and drive continuous sales growth\\n\\n Demonstrating expertise in database management, user interface development, web testing, and security vulnerabilities testing\\n\\n Holding a degree in Computer Science as well as proficiency in various database programs\\n\\n Thriving in fast-paced, challenging environments with minimal downtime\\n\\nWith my proven record of managing all facets of design and development, along with my exceptional interpersonal and analytical talents, I am ready to provide outstanding service for The Hive. I look forward to discussing this position and my qualifications with you in further detail.\\n\\nThank you for your consideration.\\n\\n\\n====================\\n As a highly skilled and accomplished UI/UX professional with more than 13 years of experience designing and implementing innovative new products and solutions for the user interface and design industries, I am confident in my ability to provide outstanding UX design service to your company as your next UI designer.\\n\\nMy career accomplishments consist of more than 7 years of experience as an UI designer for Waggle and Photoshop. From overseeing UI design projects and presenting interface suggestions to overseeing project management and creating user-friendly interface prototypes, I excelled at providing top-level administrative management, problem solving, and comprehensive project oversight that has continued to this day. Additionally, my superior communication and organization skills are certain to render me an immediate asset to your team.\\n\\nThe following achievements demonstrate my qualification for this position:\\n\\n Responsible for UI and UX design projects for Waggle and Photoshop for nearly nine years, meeting all deadlines by developing user forums, e-commerce store product guides, and design updates\\n\\n Oversaw an entire system for the design of a new user interface for the online retail store Goodly, Inc.; overhauled site design and layout for interface for redesign and expansion\\n\\n Designed interface prototypes for online retail store Goodly, Inc.; used visual design software to interface and customize user interface for product knowledge and product knowledge base\\n\\n Oversaw UI/UX and web design projects for two main product knowledge gaps, one for the web and the other for mobile applications\\n\\n Increased overall project cost for web and web design efforts by more than $10K through prior design and development work\\n\\n Increased project scope by 15% for mobile application design and development for web application design and development\\n\\nMy proven dedication to optimizing UI and UX design for desired user experiences and organizational needs, along with my exceptional communication and organization skills, will contribute immensely to the success of your company. Thank you for your consideration, and I look forward to speaking with you soon.\\n\\n\\n====================\\n'}}\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = split_data(pb.to_dict())\n",
    "\n",
    "print(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e325eae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 3 samples for training, and 3 samples for validation testing'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data = split_data(pb.to_dict())\n",
    "\n",
    "train_dataset = myDataset(train_data, tokenizer)\n",
    "##future try using val data instead of train data here\n",
    "val_dataset = myDataset(train_data, tokenizer, randomize=False)\n",
    "\n",
    "f'There are {len(train_dataset) :,} samples for training, and {len(val_dataset) :,} samples for validation testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612e94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/home/absconditus/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 32\n",
      "  Total optimization steps = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4/4 00:32, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/home/absconditus/Documents/Github/Python Projects/jupyter/TF LSTM RNN for cover letter generation/resulto\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCHSIZE,\n",
    "    per_device_eval_batch_size=TRAIN_BATCHSIZE,\n",
    "    gradient_accumulation_steps=BATCH_UPDATE,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    #fp16=True,\n",
    "    #fp16_opt_level=APEX_OPT_LEVEL,\n",
    "    warmup_steps=WARMUP_STEPS,    \n",
    "    learning_rate=LR,\n",
    "    adam_epsilon=EPS,\n",
    "    weight_decay=0.01,        \n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,     \n",
    ")\n",
    "\n",
    "#---------------------------------------------------#\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,    \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "#---------------------------------------------------#\n",
    "trainer.train()\n",
    "trainer.save_model()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ac593",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\n",
    "model = get_model(tokenizer, \n",
    "                  special_tokens=SPECIAL_TOKENS)\n",
    "                  #load_model_path='pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e84c5dc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46823/2331963406.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "title = \"We got a lot of grief when our photo became a meme\"\n",
    "keywords = ['train', 'lads', 'drinking', 'picture', 'funny', 'instagram']\n",
    "kw = myDataset.join_keywords(keywords, randomize=False)\n",
    "\n",
    "prompt = SPECIAL_TOKENS['bos_token'] + title + \\\n",
    "         SPECIAL_TOKENS['sep_token'] + kw + SPECIAL_TOKENS['sep_token']\n",
    "         \n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "device = torch.device(\"cuda\")\n",
    "generated = generated.to(device)\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "374f54d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_46823/1321029287.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Top-p (nucleus) text generation (10 samples):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m sample_outputs = model.generate(generated, \n\u001b[0m\u001b[1;32m      3\u001b[0m                                 \u001b[0mdo_sample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                 \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAXLEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Top-p (nucleus) text generation (10 samples):\n",
    "sample_outputs = model.generate(generated, \n",
    "                                do_sample=True,   \n",
    "                                min_length=50, \n",
    "                                max_length=MAXLEN,\n",
    "                                top_k=30,                                 \n",
    "                                top_p=0.7,        \n",
    "                                temperature=0.9,\n",
    "                                repetition_penalty=2.0,\n",
    "                                num_return_sequences=10\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "    a = len(title) + len(','.join(keywords))    \n",
    "    print(\"{}: {}\\n\\n\".format(i+1,  text[a:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e044f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam-search text generation:\n",
    "sample_outputs = model.generate(generated, \n",
    "                                do_sample=True,   \n",
    "                                max_length=MAXLEN,                                                      \n",
    "                                num_beams=5,\n",
    "                                repetition_penalty=5.0,\n",
    "                                early_stopping=True,      \n",
    "                                num_return_sequences=1\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "    a = len(title) + len(','.join(keywords))    \n",
    "    print(\"{}: {}\\n\\n\".format(i+1,  text[a:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefd5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenier()\n",
    "model = get_model(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45eee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = title\n",
    "\n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "device = torch.device(\"cuda\")\n",
    "generated = generated.to(device)\n",
    "\n",
    "model.eval()\n",
    "sample_outputs = model.generate(generated, \n",
    "                                do_sample=True,   \n",
    "                                max_length=MAXLEN,                                                      \n",
    "                                num_beams=5,\n",
    "                                repetition_penalty=5.0,\n",
    "                                early_stopping=True,      \n",
    "                                num_return_sequences=1\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Resuyay",
   "language": "python",
   "name": "resuyay"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
